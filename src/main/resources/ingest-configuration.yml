name: "" # Unique name for data ingestion
environment: "" # Environment identifier
pipeline: "" # Pipeline name must match a directory in the the provided template folder (ie incremental-with-kudu, kudu-table-ddl, truncate-reload)
source:
  type: Jdbc # Data source type Jdbc or Glue
  url: "" # JDBC Connection url
  username: "" # JDBC Username
  passwordFile: "/" # HDFS location of password file
  schema: "" # JDBC Schema / database name
  tableTypes: # Controls the types of tables included in the configuration output
    - table
# OPTIONAL: Controls the collection of location and inputformat from hive/impala. Default value is false.
#  includeHiveAttributes: true
# OPTIONAL: Used to ignore the tables. In case tables(used for table whitelisting) and ignoreTables are used simultaneously then tables are ignored from whitelisted tables.
#  ignoreTables:
#    - table1
#    - table2
# OPTIONAL: This is used to manage allowed schema changes. If this parameter is not provided in config, by default it includes all the values from enum SchemaChanges
#  validSchemaChanges:
#    - COLUMN_ADD
#    - UPDATE_COLUMN_COMMENT
# OPTIONAL: used to fetch snowflake tables details in batch of value provided. Default value is 10.
#  batchTableCount: 11
# OPTIONAL: table whitelisting
#  tables:
#    - table1
#    - table2
# OPTIONAL: override metadata
#  userDefinedTable:
#    - name: table1
#      type: Snowflake
#    - name: table2
#      type: Snowflake
destination:
  type: Snowflake # Destination type Snowflake or Hadoop
  snowSqlCommand: snowsql -c <connection> # SnowSQL connection
  storagePath: "" # S3 or Azure storage url
  storageIntegration: "" # Snowflake storage integration name (Storage integrations are not created with Streamliner)
  warehouse: "" # Snowflake warehouse name (Warehouses are not created with Streamliner)
  taskSchedule: "" # https://docs.snowflake.com/en/user-guide/tasks-intro.html#task-scheduling-and-daylight-saving-time
  stageName: "" # Snowflake external stage name (Stages are not created with Streamliner)
  fileFormat: # Snowflake file format https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html
    name: ""
    options:
      type: ""
  stagingDatabase: # Staging database
    name: ""
    schema: ""
  reportingDatabase: # Reporting database
    name: ""
    schema: ""
#destination:
#   type: Hadoop
#  impalaShellCommand: "" # Impala shell command copied from CM
#  stagingDatabase:
#    name: "" # Staging database
#    path: "" # Staging database hdfs path
#  reportingDatabase:
#    name: "" # Reporting database name (these can be the same as staging database if template allows)
#    path: "" # Reporting database path (these can be the same as staging database if template allows)